//! Integration tests for QLoRA training functionality.
//!
//! Tests cover:
//! - Standard optimizer trains and updates weights (PR #10 r2700563687)
//! - Paged optimizer trains with correct CPUâ†”GPU paging (PR #10 r2700563685)
//! - Memory limits are enforced when set (PR #10 r2700563689)

use candle_core::{DType, Device, Tensor};
use qlora_rs::{
    training::{PagedAdamW, PagedAdamWState, QLoraTrainer, QLoraTrainingConfig},
    QLoraConfig, QuantizedLinear,
};

/// Test that standard AdamW optimizer properly trains LoRA weights.
///
/// Verifies fix for PR #10 comment r2700563687: "Standard AdamW created from empty VarMap"
#[test]
fn test_standard_optimizer_trains_weights() {
    let device = Device::Cpu;

    // Create trainer with standard optimizer (paging disabled)
    let config = QLoraTrainingConfig {
        use_paged_optimizer: false,
        ..Default::default()
    };
    let trainer = QLoraTrainer::new(config, device.clone());

    // Create a layer using the trainer's VarBuilder for gradient tracking
    let qlora_config = QLoraConfig::preset_qv_bf16(8, 16);

    // Create test weight tensor
    let weight = Tensor::randn(0f32, 1f32, (64, 64), &device).unwrap();

    // Use VarBuilder constructor to register params in VarMap
    // Scope the VarBuilder borrow so it's dropped before init_optimizer
    let layer = {
        let vb = trainer.var_builder();
        QuantizedLinear::from_weight_with_varbuilder(&weight, None, &qlora_config, vb.pp("layer0"))
            .unwrap()
    };

    // Get initial LoRA weights
    let (initial_a, initial_b) = layer.lora_weights();
    let _initial_a_sum = initial_a.sum_all().unwrap().to_scalar::<f32>().unwrap();
    let _initial_b_sum = initial_b.sum_all().unwrap().to_scalar::<f32>().unwrap();

    // Initialize optimizer - should NOT fail with empty VarMap now
    let layers: Vec<&QuantizedLinear> = vec![&layer];
    let mut trainer = trainer;
    let result = trainer.init_optimizer(&layers);

    // This should succeed because VarBuilder registered params
    assert!(
        result.is_ok(),
        "init_optimizer should succeed with VarBuilder-created layers: {:?}",
        result.err()
    );
}

/// Test that paged optimizer state tracks memory correctly.
///
/// Verifies fix for PR #10 comment r2700563689: Memory limits tracked but not enforced
#[test]
fn test_paged_optimizer_memory_tracking() {
    let mut state = PagedAdamWState::new(1024 * 1024, 0); // Unlimited
    let device = Device::Cpu;

    // Initialize some parameters
    state.init_param("param1", &[64, 64], &device).unwrap();
    state.init_param("param2", &[64, 64], &device).unwrap();
    state.init_param("param3", &[64, 64], &device).unwrap();

    // Memory should start at 0 (states are on CPU)
    assert_eq!(state.current_gpu_usage, 0, "Initial GPU usage should be 0");

    // Page param1 to GPU (note: this is conceptual on CPU device)
    let _ = state.page_to_device("param1", &device).unwrap();
    let usage_after_param1 = state.current_gpu_usage;
    assert!(
        usage_after_param1 > 0,
        "GPU usage should increase after paging"
    );
    assert!(
        state.is_gpu_resident("param1"),
        "param1 should be GPU resident"
    );

    // Page param2 to GPU
    let _ = state.page_to_device("param2", &device).unwrap();
    let usage_after_param2 = state.current_gpu_usage;
    assert!(
        usage_after_param2 > usage_after_param1,
        "GPU usage should increase further"
    );
    assert!(
        state.is_gpu_resident("param2"),
        "param2 should be GPU resident"
    );

    // Page param1 back to CPU
    let (exp_avg, exp_avg_sq) = state.page_to_device("param1", &device).unwrap();
    state.page_to_cpu("param1", &exp_avg, &exp_avg_sq).unwrap();
    let usage_after_cpu = state.current_gpu_usage;
    assert!(
        usage_after_cpu < usage_after_param2,
        "GPU usage should decrease after paging to CPU"
    );
    assert!(
        !state.is_gpu_resident("param1"),
        "param1 should no longer be GPU resident"
    );
}

/// Test that memory limits are enforced with LRU eviction.
///
/// Verifies fix for PR #10 comment r2700563689: Memory limits enforced
#[test]
fn test_paged_optimizer_memory_limit_enforcement() {
    // Set a very small memory limit to force eviction
    // Each param is 64*64*4*2 = 32KB (2 states, f32)
    let param_size = 64 * 64 * 4 * 2;
    let max_memory = param_size * 2; // Allow only 2 params on GPU

    let mut state = PagedAdamWState::new(1024, max_memory);
    let device = Device::Cpu;

    // Initialize 3 parameters
    state.init_param("param1", &[64, 64], &device).unwrap();
    state.init_param("param2", &[64, 64], &device).unwrap();
    state.init_param("param3", &[64, 64], &device).unwrap();

    // Page all 3 to GPU - should trigger eviction on param3
    let _ = state.page_to_device("param1", &device).unwrap();
    let _ = state.page_to_device("param2", &device).unwrap();

    // At this point, GPU should be near limit
    let _usage_before_param3 = state.current_gpu_usage;

    // Paging param3 should evict param1 (LRU)
    let _ = state.page_to_device("param3", &device).unwrap();

    // After eviction, usage should still be within limits
    assert!(
        state.current_gpu_usage <= max_memory,
        "GPU usage ({}) should be within limit ({})",
        state.current_gpu_usage,
        max_memory
    );

    // param1 should be evicted (was LRU)
    assert!(
        !state.is_gpu_resident("param1"),
        "param1 (LRU) should be evicted when adding param3 over limit"
    );
}

/// Test paged optimizer actually performs parameter updates.
///
/// Verifies fix for PR #10 comment r2700563685: Paged optimizer never used in training step
#[test]
fn test_paged_optimizer_performs_updates() {
    let device = Device::Cpu;

    // Create paged optimizer
    let mut optimizer = PagedAdamW::new(0.01, 0.01, 1024 * 1024, 0);

    // Initialize with a test parameter
    let param = Tensor::ones(&[4, 4], DType::F32, &device).unwrap();
    let params = vec![("test_param".to_string(), param.clone())];
    optimizer.init(&params).unwrap();

    // Create a gradient
    let grad = Tensor::ones(&[4, 4], DType::F32, &device).unwrap();

    // Get initial param value
    let initial_sum = param.sum_all().unwrap().to_scalar::<f32>().unwrap();

    // Perform optimizer step
    let mut param_clone = param.clone();
    optimizer
        .step_param("test_param", &mut param_clone, &grad)
        .unwrap();

    // Param should have changed
    let final_sum = param_clone.sum_all().unwrap().to_scalar::<f32>().unwrap();

    assert!(
        (final_sum - initial_sum).abs() > 1e-6,
        "Parameter should be updated after optimizer step: initial={}, final={}",
        initial_sum,
        final_sum
    );
}

/// Test LRU ordering is maintained correctly.
#[test]
fn test_lru_order_tracking() {
    let mut state = PagedAdamWState::new(1024, 0); // Unlimited
    let device = Device::Cpu;

    // Initialize params in order
    state.init_param("a", &[4, 4], &device).unwrap();
    state.init_param("b", &[4, 4], &device).unwrap();
    state.init_param("c", &[4, 4], &device).unwrap();

    // Access in different order: c, a, b
    let _ = state.page_to_device("c", &device).unwrap();
    let _ = state.page_to_device("a", &device).unwrap();
    let _ = state.page_to_device("b", &device).unwrap();

    // All three should be GPU resident
    assert!(state.is_gpu_resident("a"), "a should be GPU resident");
    assert!(state.is_gpu_resident("b"), "b should be GPU resident");
    assert!(state.is_gpu_resident("c"), "c should be GPU resident");
    assert_eq!(
        state.gpu_resident_count(),
        3,
        "All 3 params should be GPU resident"
    );

    // Access 'c' again to make it most recent
    let _ = state.page_to_device("c", &device).unwrap();

    // Still all three should be GPU resident
    assert_eq!(
        state.gpu_resident_count(),
        3,
        "All 3 params should still be GPU resident"
    );
}

/// Test trainer with paged optimizer enabled.
#[test]
fn test_trainer_with_paged_optimizer() {
    let device = Device::Cpu;

    // Create trainer with paged optimizer
    let config = QLoraTrainingConfig {
        use_paged_optimizer: true,
        ..Default::default()
    };
    let trainer = QLoraTrainer::new(config, device.clone());

    // Create a layer with VarBuilder - scope it to drop the borrow
    let qlora_config = QLoraConfig::preset_qv_bf16(8, 16);
    let weight = Tensor::randn(0f32, 1f32, (64, 64), &device).unwrap();

    let layer = {
        let vb = trainer.var_builder();
        QuantizedLinear::from_weight_with_varbuilder(&weight, None, &qlora_config, vb.pp("layer0"))
            .unwrap()
    };

    let layers: Vec<&QuantizedLinear> = vec![&layer];

    // Initialize should succeed
    let mut trainer = trainer;
    let result = trainer.init_optimizer(&layers);
    assert!(
        result.is_ok(),
        "Paged optimizer init should succeed: {:?}",
        result.err()
    );

    // Check memory stats are available
    let stats = trainer.optimizer_memory_stats();
    assert!(
        stats.is_some(),
        "Memory stats should be available for paged optimizer"
    );
}

/// Test that init_optimizer fails without VarBuilder-created layers.
#[test]
fn test_init_optimizer_fails_without_varbuilder() {
    let device = Device::Cpu;

    // Create trainer
    let config = QLoraTrainingConfig {
        use_paged_optimizer: false,
        ..Default::default()
    };
    let mut trainer = QLoraTrainer::new(config, device.clone());

    // Create a layer WITHOUT using trainer's VarBuilder
    let qlora_config = QLoraConfig::preset_qv_bf16(8, 16);
    let layer = QuantizedLinear::new(64, 64, &qlora_config, &device).unwrap();

    let layers: Vec<&QuantizedLinear> = vec![&layer];

    // Initialize should FAIL because VarMap is empty
    let result = trainer.init_optimizer(&layers);
    assert!(
        result.is_err(),
        "init_optimizer should fail without VarBuilder-created layers"
    );
}
